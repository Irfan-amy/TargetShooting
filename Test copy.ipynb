{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start point:  (25, 242)\n",
      "End point:  (359, 354)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "cap = cv2.VideoCapture(\"Camp.mp4\")\n",
    "\n",
    "# Read a frame from the video\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Check if the video has ended\n",
    "if not ret:\n",
    "    print(\"Error: Could not read frame from video.\")\n",
    "    exit()\n",
    "\n",
    "frame = cv2.resize(frame, (500, 500))\n",
    "\n",
    "# Create a copy of the original frame\n",
    "clone = frame.copy()\n",
    "\n",
    "# Define the starting and ending points for cropping\n",
    "start_point = None\n",
    "end_point = None\n",
    "cropping = False\n",
    "\n",
    "# Define the mouse callback function\n",
    "def mouse_crop(event, x, y, flags, param):\n",
    "    global start_point, end_point, cropping\n",
    "    \n",
    "    # Start cropping when the left mouse button is pressed\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        start_point = (x, y)\n",
    "        print(\"Start point: \", start_point)\n",
    "        cropping = True\n",
    "    \n",
    "    # End cropping when the left mouse button is released\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        end_point = (x, y)\n",
    "        cropping = False\n",
    "        print(\"End point: \", end_point)\n",
    "        \n",
    "        # Draw the rectangle around the cropped area\n",
    "        cv2.rectangle(clone, start_point, end_point, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Cropped Image\", clone)\n",
    "        \n",
    "        # Crop the original frame using the start and end points\n",
    "        cropped = frame[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "        cv2.imshow(\"Cropped Image\", cropped)\n",
    "\n",
    "# Create a window and set the mouse callback function\n",
    "cv2.namedWindow(\"Cropped Image\")\n",
    "cv2.setMouseCallback(\"Cropped Image\", mouse_crop)\n",
    "\n",
    "# Display the original frame\n",
    "cv2.imshow(\"Cropped Image\", clone)\n",
    "\n",
    "# Wait for a key press\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "cap = cv2.VideoCapture(\"Camp.mp4\")\n",
    "cv2.namedWindow(\"HSV Mask\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"HSV Mask\",540,250)\n",
    "\n",
    "# Create trackbars for hue, saturation, and value\n",
    "cv2.createTrackbar(\"LHue\", \"HSV Mask\", 0, 255, lambda x: x)\n",
    "cv2.createTrackbar(\"UHue\", \"HSV Mask\", 254, 255, lambda x: x)\n",
    "cv2.createTrackbar(\"Saturation\", \"HSV Mask\", 0, 255, lambda x: x)\n",
    "cv2.createTrackbar(\"Value\", \"HSV Mask\", 0, 255, lambda x: x)\n",
    "cv2.createTrackbar(\"Value1\", \"HSV Mask\", 0, 255, lambda x: x)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the video has ended\n",
    "    if not ret:\n",
    "        cap = cv2.VideoCapture(\"Camp.mp4\")\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (500, 500))\n",
    "\n",
    "    frame = frame[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "\n",
    "\n",
    "    hsv_img = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Get the current values of the trackbars\n",
    "    uhue = cv2.getTrackbarPos(\"UHue\", \"HSV Mask\")\n",
    "    lhue = cv2.getTrackbarPos(\"LHue\", \"HSV Mask\")\n",
    "    sat = cv2.getTrackbarPos(\"Saturation\", \"HSV Mask\")\n",
    "    val = cv2.getTrackbarPos(\"Value\", \"HSV Mask\")\n",
    "\n",
    "    # Define the range of HSV values to mask\n",
    "    lower_bound = np.array([lhue, sat, val])\n",
    "    upper_bound = np.array([uhue, 255, 255])\n",
    "\n",
    "    # Create a mask for the desired HSV range\n",
    "    mask = cv2.inRange(hsv_img,  lower_bound, upper_bound)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    # Display the original image\n",
    "    cv2.imshow(\"Original\", frame)\n",
    "\n",
    "    # Display the result of applying the mask\n",
    "    cv2.imshow(\"Test\", result)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "cap = cv2.VideoCapture(\"Camp.mp4\")\n",
    "cv2.namedWindow(\"HSV Mask\")\n",
    "\n",
    "# Create trackbars for hue, saturation, and value\n",
    "cv2.createTrackbar(\"LHue\", \"HSV Mask\", 0, 255, lambda x: x)\n",
    "cv2.createTrackbar(\"UHue\", \"HSV Mask\", 1, 255, lambda x: x)\n",
    "cv2.createTrackbar(\"Saturation\", \"HSV Mask\", 0, 255, lambda x: x)\n",
    "cv2.createTrackbar(\"Value\", \"HSV Mask\", 0, 255, lambda x: x)\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the video has ended\n",
    "    if not ret:\n",
    "        cap = cv2.VideoCapture(\"Camp.mp4\")\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (500, 500))\n",
    "\n",
    "    frame = frame[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "    # Create a mask for the color range\n",
    "    omask = cv2.inRange(hsv_frame, lower_bound, upper_bound)\n",
    "\n",
    "    # Invert the omask\n",
    "    omask = cv2.bitwise_not(omask)\n",
    "\n",
    "    # Remove the color from the image using the inverted omask\n",
    "    frame = cv2.bitwise_and(frame, frame, mask=omask)\n",
    "\n",
    "\n",
    "    hsv_img = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Create a window to display the sliders\n",
    "\n",
    "\n",
    "\n",
    "    # Get the current values of the trackbars\n",
    "    uhue = cv2.getTrackbarPos(\"UHue\", \"HSV Mask\")\n",
    "    lhue = cv2.getTrackbarPos(\"LHue\", \"HSV Mask\")\n",
    "    sat = cv2.getTrackbarPos(\"Saturation\", \"HSV Mask\")\n",
    "    val = cv2.getTrackbarPos(\"Value\", \"HSV Mask\")\n",
    "\n",
    "    # Define the range of HSV values to mask\n",
    "    lower = np.array([lhue, sat, val])\n",
    "    upper = np.array([uhue, 255, 255])\n",
    "\n",
    "    # Create a mask for the desired HSV range\n",
    "    mask = cv2.inRange(hsv_img, lower, upper)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    # Display the original image\n",
    "    cv2.imshow(\"Original\", frame)\n",
    "\n",
    "    # Display the result of applying the mask\n",
    "    cv2.imshow(\"Test\", result)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "cap = cv2.VideoCapture(\"Camp.mp4\")\n",
    "cv2.namedWindow(\"HSV Mask\")\n",
    "cv2.createTrackbar(\"Area\", \"HSV Mask\", 0, 200, lambda x: x)\n",
    "cv2.createTrackbar(\"Area2\", \"HSV Mask\", 0, 200, lambda x: x)\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "# Check if the video has ended\n",
    "    if not ret:\n",
    "        cap = cv2.VideoCapture(\"Camp.mp4\")\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (500, 500))\n",
    "\n",
    "    frame = frame[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "    # Create a mask for the color range\n",
    "    omask = cv2.inRange(hsv_frame, lower_bound, upper_bound)\n",
    "\n",
    "    # Invert the omask\n",
    "    omask = cv2.bitwise_not(omask)\n",
    "\n",
    "    # Remove the color from the image using the inverted omask\n",
    "    frame = cv2.bitwise_and(frame, frame, mask=omask)\n",
    "\n",
    "    hsv_img = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # Create a mask for the desired HSV range\n",
    "    mask = cv2.inRange(hsv_img, lower, upper)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "\n",
    "\n",
    "    result2 = result.copy()\n",
    "    area_threshold1 = cv2.getTrackbarPos(\"Area\", \"HSV Mask\")\n",
    "    area_threshold2 = cv2.getTrackbarPos(\"Area2\", \"HSV Mask\")\n",
    "    contours,_ = cv2.findContours(mask,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        if area_threshold1 < cv2.contourArea(c) < area_threshold2:\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(result2,(x-10,y-10), ((x+w)+10,(y+h)+10),(0,255,0),1)\n",
    "\n",
    "\n",
    "    # Display the result of applying the mask\n",
    "    cv2.imshow(\"Test\", result2)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'area_threshold1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m contours:\n\u001b[0;32m     50\u001b[0m     \u001b[39mprint\u001b[39m(cv2\u001b[39m.\u001b[39mcontourArea(c))\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mif\u001b[39;00m area_threshold1 \u001b[39m<\u001b[39m cv2\u001b[39m.\u001b[39mcontourArea(c) \u001b[39m<\u001b[39m area_threshold2:\n\u001b[0;32m     52\u001b[0m         x,y,w,h \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mboundingRect(c)\n\u001b[0;32m     53\u001b[0m         cv2\u001b[39m.\u001b[39mrectangle(result2,(x\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m,y\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m), ((x\u001b[39m+\u001b[39mw)\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m,(y\u001b[39m+\u001b[39mh)\u001b[39m+\u001b[39m\u001b[39m10\u001b[39m),(\u001b[39m0\u001b[39m,\u001b[39m255\u001b[39m,\u001b[39m0\u001b[39m),\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'area_threshold1' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"Camp.mp4\")\n",
    "while True:\n",
    "    \n",
    "\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    \n",
    "\n",
    "    # Check if the video has ended\n",
    "    if not ret:\n",
    "        cap = cv2.VideoCapture(\"Camp.mp4\")\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (500, 500))\n",
    "    org = frame.copy()\n",
    "    cv2.imshow(\"Original\", frame)\n",
    "\n",
    "    frame = frame[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
    "\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "    # Create a mask for the color range\n",
    "    omask = cv2.inRange(hsv_frame, lower_bound, upper_bound)\n",
    "\n",
    "    # Invert the omask\n",
    "    omask = cv2.bitwise_not(omask)\n",
    "\n",
    "    # Remove the color from the image using the inverted omask\n",
    "    frame = cv2.bitwise_and(frame, frame, mask=omask)\n",
    "\n",
    "    hsv_img = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)    \n",
    "    # Create a mask for the desired HSV range   \n",
    "    mask = cv2.inRange(hsv_img, lower, upper)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "\n",
    "    result2 = result.copy()\n",
    "    contours,_ = cv2.findContours(mask,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        print(cv2.contourArea(c))\n",
    "        if area_threshold1 < cv2.contourArea(c) < area_threshold2:\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(result2,(x-10,y-10), ((x+w)+10,(y+h)+10),(0,255,0),1)\n",
    "\n",
    "    \n",
    "    # Display the result of applying the mask\n",
    "    cv2.imshow(\"HSV Mask\", mask)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    time.sleep(0.2)\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load an image\n",
    "cap = cv2.VideoCapture(\"Camp.mp4\")\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the video has ended\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (500, 500))\n",
    "\n",
    "    # Convert the image to the RGB color space\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Convert the image to the LAB color space\n",
    "    lab_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Convert the image to the LUV color space\n",
    "    luv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2LUV)\n",
    "\n",
    "    # Convert the image to the YCrCb color space\n",
    "    ycrcb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the original image\n",
    "    cv2.imshow(\"Original\", frame)\n",
    "\n",
    "    # Display the image in the RGB color space\n",
    "    cv2.imshow(\"RGB\", rgb_frame)\n",
    "\n",
    "    # Display the image in the HSV color space\n",
    "    cv2.imshow(\"HSV\", hsv_frame)\n",
    "\n",
    "    # Display the image in the LAB color space\n",
    "    cv2.imshow(\"LAB\", lab_frame)\n",
    "\n",
    "    # Display the image in the LUV color space\n",
    "    cv2.imshow(\"LUV\", luv_frame)\n",
    "\n",
    "    # Display the image in the YCrCb color space\n",
    "    cv2.imshow(\"YCrCb\", ycrcb_frame)\n",
    "\n",
    "    # Display the image in grayscale\n",
    "    cv2.imshow(\"Grayscale\", gray_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# Load an image\n",
    "cap = cv2.VideoCapture(\"Camp.mp4\")\n",
    "\n",
    "# Read a frame from the video\n",
    "ret, img = cap.read()\n",
    "\n",
    "# Check if the video has ended\n",
    "if not ret:\n",
    "    break\n",
    "\n",
    "# Convert the image to the HSV color space\n",
    "hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the lower and upper bounds of the color you want to exclude\n",
    "lower_bound = np.array([65, 0, 0])\n",
    "upper_bound = np.array([97, 255, 255])\n",
    "\n",
    "# Create a mask for the color range\n",
    "mask = cv2.inRange(hsv_img, lower_bound, upper_bound)\n",
    "\n",
    "# Invert the mask\n",
    "mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Remove the color from the image using the inverted mask\n",
    "img = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "# Display the original image\n",
    "cv2.imshow(\"Original\", img)\n",
    "\n",
    "# Wait for a key press\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "img = cv2.imread(\"path/to/image.jpg\")\n",
    "\n",
    "# Convert the image to the RGB color space\n",
    "rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert the image to the HSV color space\n",
    "hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Convert the image to the LAB color space\n",
    "lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "# Convert the image to the LUV color space\n",
    "luv_img = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "\n",
    "# Convert the image to the YCrCb color space\n",
    "ycrcb_img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "# concatenate the images horizontally\n",
    "images_list = [rgb_img, hsv_img, gray_img, lab_img, luv_img, ycrcb_img]\n",
    "side_by_side = np.concatenate(images_list, axis=1)\n",
    "\n",
    "# Display the concatenated images\n",
    "cv2.imshow(\"Side by Side\", side_by_side)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load an image\n",
    "img = cv2.imread(\"C:\\Work\\Intern\\Image Classification\\Preprocess\\Stand\\VID20230116131337_frame_0_Stand.jpg\")\n",
    "\n",
    "# Convert the image to the RGB color space\n",
    "rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert the image to the HSV color space\n",
    "hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Concatenate the images horizontally\n",
    "side_by_side = cv2.hconcat([rgb_img, hsv_img, gray_img])\n",
    "\n",
    "# Display the concatenated images\n",
    "cv2.imshow(\"Side by Side\", side_by_side)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "lower_red = np.array([0, 50, 50])\n",
    "upper_red = np.array([10, 255, 255])\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "base_model = keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# Freeze all layers in the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add a new classifier on top of the base model\n",
    "x = base_model.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "predictions = keras.layers.Dense(2, activation='softmax')(x)\n",
    "model = keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load the train and validation data\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'Split_Preprocess/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Create a data generator for the validation dataset\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    'Split_Preprocess/val',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = datagen.flow(X, y, batch_size=32)\n",
    "\n",
    "# Get a batch of images and labels\n",
    "X_batch, y_batch = next(gen)\n",
    "\n",
    "# Plot the first image in the batch\n",
    "plt.imshow(X_batch[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('model2.h5')\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture('C:\\Work\\Intern\\Image Classification\\VID20230116131651.mp4')\n",
    "\n",
    "labels = [\"Fall\",\"Stand\"]\n",
    "count = 0\n",
    "label = 0\n",
    "confidence = 0\n",
    "# Get the frames from the video\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.resize(frame, (500, 500))\n",
    "    \n",
    "    if count % 3 == 0:\n",
    "        # Preprocess the frame\n",
    "        frame2 = cv2.resize(frame, (224, 224))\n",
    "        # frame = frame.astype(\"float32\") / 255.0\n",
    "        frame2 = np.expand_dims(frame2, axis=0)\n",
    "        \n",
    "        \n",
    "        # Use the model to predict the label of the frame\n",
    "        predictions = model.predict(frame2)\n",
    "        \n",
    "        # Get the class label with the highest probability\n",
    "        confidence =  round(np.max(predictions[0]),3)\n",
    "        print('%.2f' % round(np.min(predictions[0]),3), '%.2f' % round(np.max(predictions[0]),3))\n",
    "        if confidence > 0.5:\n",
    "            label = np.argmax(predictions[0])\n",
    "        # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Draw the label on the frame\n",
    "        \n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "    cv2.putText(frame, str(labels[label]) + f\" (%.2f)\" % confidence, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    count+=1\n",
    "    # Exit if the user presses 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=lambda x: cv2.merge([cv2.inRange(cv2.cvtColor(x, cv2.COLOR_BGR2HSV), lower_red, upper_red)]*3))\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'Split_Preprocess/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "X_batch, y_batch = next(train_generator)\n",
    "plt.imshow(X_batch[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "  \n",
    "# Create a VideoCapture object and read from input file\n",
    "cap = cv2.VideoCapture('Dataset\\Stand\\VID20230116131556.mp4')\n",
    "  \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error opening video file\")\n",
    "  \n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "      \n",
    "# Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "    # Display the resulting frame\n",
    "        cv2.imshow('Frame', frame)\n",
    "          \n",
    "    # Press Q on keyboard to exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "  \n",
    "# Break the loop\n",
    "    else:\n",
    "        break\n",
    "  \n",
    "# When everything done, release\n",
    "# the video capture object\n",
    "cap.release()\n",
    "  \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
